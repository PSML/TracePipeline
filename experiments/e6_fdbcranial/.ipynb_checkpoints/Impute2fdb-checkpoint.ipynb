{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "File b'../../datasources/fdb/cranial.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-97f6c9eba57a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Import cranial database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../datasources/fdb/cranial.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#Drop categorical data. We'll focus on measurement data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tu/anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tu/anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tu/anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tu/anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/tu/anaconda/lib/python3.4/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: File b'../../datasources/fdb/cranial.csv' does not exist"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "#Import cranial database \n",
    "df = pd.read_csv('../../datasources/fdb/cranial.csv')\n",
    "\n",
    "#Drop categorical data. We'll focus on measurement data.\n",
    "del df['DB']\n",
    "del df['Item']\n",
    "del df['ID']\n",
    "del df['ContNum']\n",
    "del df['FDN']\n",
    "del df['Pop']\n",
    "del df['PopSex']\n",
    "del df['Ethnicity'] #Probably really important.\n",
    "del df['BirthYear']\n",
    "del df['Age'] #Probably really important.\n",
    "del df['Comments']\n",
    "\n",
    "rows, cols = df.shape \n",
    "print(\"Starting with\", rows, \"individuals and\", cols, \"features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique entries.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "M      3187\n",
       "F      2095\n",
       "N        58\n",
       "NaN       2\n",
       "Name: Sex, dtype: int64"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Consider our target col, Sex.\n",
    "print(\"Unique entries.\")\n",
    "df['Sex'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/numpy/lib/function_base.py:3823: RuntimeWarning: Invalid value encountered in percentile\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>GOL</th>\n",
       "      <th>NOL</th>\n",
       "      <th>BNL</th>\n",
       "      <th>BBH</th>\n",
       "      <th>XCB</th>\n",
       "      <th>XFB</th>\n",
       "      <th>WFB</th>\n",
       "      <th>ZYB</th>\n",
       "      <th>AUB</th>\n",
       "      <th>...</th>\n",
       "      <th>MAN</th>\n",
       "      <th>BABR</th>\n",
       "      <th>BANA</th>\n",
       "      <th>BAPR</th>\n",
       "      <th>UFHT</th>\n",
       "      <th>UFBR</th>\n",
       "      <th>ORBR</th>\n",
       "      <th>BIOB</th>\n",
       "      <th>INTB</th>\n",
       "      <th>MOW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5282.000000</td>\n",
       "      <td>5200.000000</td>\n",
       "      <td>4396.000000</td>\n",
       "      <td>5177.000000</td>\n",
       "      <td>5182.000000</td>\n",
       "      <td>5196.000000</td>\n",
       "      <td>4395.000000</td>\n",
       "      <td>2622.000000</td>\n",
       "      <td>5096.000000</td>\n",
       "      <td>5106.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>518.000000</td>\n",
       "      <td>636.000000</td>\n",
       "      <td>607.000000</td>\n",
       "      <td>574.000000</td>\n",
       "      <td>2115.000000</td>\n",
       "      <td>1605.000000</td>\n",
       "      <td>453.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.206740</td>\n",
       "      <td>180.397500</td>\n",
       "      <td>177.689945</td>\n",
       "      <td>100.143906</td>\n",
       "      <td>133.846584</td>\n",
       "      <td>137.568129</td>\n",
       "      <td>114.752673</td>\n",
       "      <td>94.898932</td>\n",
       "      <td>129.449372</td>\n",
       "      <td>120.855660</td>\n",
       "      <td>...</td>\n",
       "      <td>124.990347</td>\n",
       "      <td>136.886792</td>\n",
       "      <td>101.494234</td>\n",
       "      <td>97.031359</td>\n",
       "      <td>70.201891</td>\n",
       "      <td>103.535826</td>\n",
       "      <td>41.008830</td>\n",
       "      <td>96.253311</td>\n",
       "      <td>20.552058</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.978489</td>\n",
       "      <td>8.838111</td>\n",
       "      <td>8.238570</td>\n",
       "      <td>5.764435</td>\n",
       "      <td>7.336864</td>\n",
       "      <td>6.811824</td>\n",
       "      <td>6.477442</td>\n",
       "      <td>4.952665</td>\n",
       "      <td>7.313785</td>\n",
       "      <td>6.763771</td>\n",
       "      <td>...</td>\n",
       "      <td>7.455211</td>\n",
       "      <td>6.889893</td>\n",
       "      <td>5.523686</td>\n",
       "      <td>6.481473</td>\n",
       "      <td>4.934519</td>\n",
       "      <td>4.827782</td>\n",
       "      <td>2.493338</td>\n",
       "      <td>4.400408</td>\n",
       "      <td>3.388348</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>131.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>145.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Sex          GOL          NOL          BNL          BBH  \\\n",
       "count  5282.000000  5200.000000  4396.000000  5177.000000  5182.000000   \n",
       "mean      0.206740   180.397500   177.689945   100.143906   133.846584   \n",
       "std       0.978489     8.838111     8.238570     5.764435     7.336864   \n",
       "min      -1.000000   131.000000   150.000000    79.000000   107.000000   \n",
       "25%      -1.000000          NaN          NaN          NaN          NaN   \n",
       "50%       1.000000          NaN          NaN          NaN          NaN   \n",
       "75%       1.000000          NaN          NaN          NaN          NaN   \n",
       "max       1.000000   211.000000   207.000000   120.000000   157.000000   \n",
       "\n",
       "               XCB          XFB          WFB          ZYB          AUB ...   \\\n",
       "count  5196.000000  4395.000000  2622.000000  5096.000000  5106.000000 ...    \n",
       "mean    137.568129   114.752673    94.898932   129.449372   120.855660 ...    \n",
       "std       6.811824     6.477442     4.952665     7.313785     6.763771 ...    \n",
       "min     116.000000    93.000000    79.000000    90.000000    98.000000 ...    \n",
       "25%            NaN          NaN          NaN          NaN          NaN ...    \n",
       "50%            NaN          NaN          NaN          NaN          NaN ...    \n",
       "75%            NaN          NaN          NaN          NaN          NaN ...    \n",
       "max     167.000000   145.000000   119.000000   158.000000   154.000000 ...    \n",
       "\n",
       "              MAN        BABR        BANA        BAPR         UFHT  \\\n",
       "count  518.000000  636.000000  607.000000  574.000000  2115.000000   \n",
       "mean   124.990347  136.886792  101.494234   97.031359    70.201891   \n",
       "std      7.455211    6.889893    5.523686    6.481473     4.934519   \n",
       "min     90.000000   84.000000   85.000000   73.000000    47.000000   \n",
       "25%           NaN         NaN         NaN         NaN          NaN   \n",
       "50%           NaN         NaN         NaN         NaN          NaN   \n",
       "75%           NaN         NaN         NaN         NaN          NaN   \n",
       "max    147.000000  156.000000  130.000000  116.000000    91.000000   \n",
       "\n",
       "              UFBR        ORBR        BIOB        INTB  MOW  \n",
       "count  1605.000000  453.000000  604.000000  413.000000  0.0  \n",
       "mean    103.535826   41.008830   96.253311   20.552058  NaN  \n",
       "std       4.827782    2.493338    4.400408    3.388348  NaN  \n",
       "min      87.000000   34.000000   81.000000    0.000000  NaN  \n",
       "25%            NaN         NaN         NaN         NaN  NaN  \n",
       "50%            NaN         NaN         NaN         NaN  NaN  \n",
       "75%            NaN         NaN         NaN         NaN  NaN  \n",
       "max     122.000000   51.000000  112.000000   29.000000  NaN  \n",
       "\n",
       "[8 rows x 111 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Clean N and Nan entries\n",
    "df = df[~(df.Sex.str.contains(\"N\") == True)]\n",
    "df = df.dropna(subset = ['Sex'])\n",
    "#Move from object to float\n",
    "df['Sex'] = df['Sex'].map({'M':1.0, 'F':-1.0})\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split into data and labels.\n",
    "X = df.drop(['Sex'], axis=1)\n",
    "y = df[['Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Split train test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167296"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4225, 110), (1057, 110), (4225, 1), (1057, 1))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances between 4225 samples\n",
      "Computing distances for sample #1/4225, elapsed time: 1.233\n",
      "Computing distances for sample #101/4225, elapsed time: 1.375\n",
      "Computing distances for sample #201/4225, elapsed time: 1.523\n",
      "Computing distances for sample #301/4225, elapsed time: 1.664\n",
      "Computing distances for sample #401/4225, elapsed time: 1.812\n",
      "No samples have sufficient overlap with sample 476\n",
      "Computing distances for sample #501/4225, elapsed time: 1.949\n",
      "Computing distances for sample #601/4225, elapsed time: 2.110\n",
      "No samples have sufficient overlap with sample 668\n",
      "Computing distances for sample #701/4225, elapsed time: 2.260\n",
      "No samples have sufficient overlap with sample 737\n",
      "Computing distances for sample #801/4225, elapsed time: 2.404\n",
      "No samples have sufficient overlap with sample 885\n",
      "Computing distances for sample #901/4225, elapsed time: 2.552\n",
      "Computing distances for sample #1001/4225, elapsed time: 2.700\n",
      "Computing distances for sample #1101/4225, elapsed time: 2.853\n",
      "Computing distances for sample #1201/4225, elapsed time: 3.008\n",
      "Computing distances for sample #1301/4225, elapsed time: 3.155\n",
      "Computing distances for sample #1401/4225, elapsed time: 3.307\n",
      "No samples have sufficient overlap with sample 1488\n",
      "Computing distances for sample #1501/4225, elapsed time: 3.449\n",
      "Computing distances for sample #1601/4225, elapsed time: 3.598\n",
      "Computing distances for sample #1701/4225, elapsed time: 3.746\n",
      "Computing distances for sample #1801/4225, elapsed time: 3.900\n",
      "Computing distances for sample #1901/4225, elapsed time: 4.053\n",
      "No samples have sufficient overlap with sample 1960\n",
      "No samples have sufficient overlap with sample 1967\n",
      "Computing distances for sample #2001/4225, elapsed time: 4.209\n",
      "Computing distances for sample #2101/4225, elapsed time: 4.349\n",
      "No samples have sufficient overlap with sample 2189\n",
      "Computing distances for sample #2201/4225, elapsed time: 4.503\n",
      "Computing distances for sample #2301/4225, elapsed time: 4.653\n",
      "Computing distances for sample #2401/4225, elapsed time: 4.800\n",
      "No samples have sufficient overlap with sample 2433\n",
      "Computing distances for sample #2501/4225, elapsed time: 4.940\n",
      "Computing distances for sample #2601/4225, elapsed time: 5.091\n",
      "Computing distances for sample #2701/4225, elapsed time: 5.245\n",
      "No samples have sufficient overlap with sample 2720\n",
      "No samples have sufficient overlap with sample 2727\n",
      "Computing distances for sample #2801/4225, elapsed time: 5.396\n",
      "No samples have sufficient overlap with sample 2893\n",
      "Computing distances for sample #2901/4225, elapsed time: 5.554\n",
      "Computing distances for sample #3001/4225, elapsed time: 5.719\n",
      "Computing distances for sample #3101/4225, elapsed time: 5.875\n",
      "Computing distances for sample #3201/4225, elapsed time: 6.037\n",
      "Computing distances for sample #3301/4225, elapsed time: 6.191\n",
      "Computing distances for sample #3401/4225, elapsed time: 6.344\n",
      "No samples have sufficient overlap with sample 3430\n",
      "Computing distances for sample #3501/4225, elapsed time: 6.499\n",
      "Computing distances for sample #3601/4225, elapsed time: 6.661\n",
      "Computing distances for sample #3701/4225, elapsed time: 6.814\n",
      "No samples have sufficient overlap with sample 3792\n",
      "Computing distances for sample #3801/4225, elapsed time: 6.966\n",
      "Computing distances for sample #3901/4225, elapsed time: 7.118\n",
      "Computing distances for sample #4001/4225, elapsed time: 7.273\n",
      "No samples have sufficient overlap with sample 4047\n",
      "Computing distances for sample #4101/4225, elapsed time: 7.437\n",
      "Computing distances for sample #4201/4225, elapsed time: 7.622\n",
      "Imputing row 1/4225 with 29 missing columns, elapsed time: 8.777\n",
      "Imputing row 101/4225 with 29 missing columns, elapsed time: 8.886\n",
      "Imputing row 201/4225 with 29 missing columns, elapsed time: 8.983\n",
      "Imputing row 301/4225 with 82 missing columns, elapsed time: 9.104\n",
      "Imputing row 401/4225 with 29 missing columns, elapsed time: 9.219\n",
      "Imputing row 501/4225 with 40 missing columns, elapsed time: 9.327\n",
      "Imputing row 601/4225 with 29 missing columns, elapsed time: 9.425\n",
      "Imputing row 701/4225 with 40 missing columns, elapsed time: 9.539\n",
      "Imputing row 801/4225 with 29 missing columns, elapsed time: 9.635\n",
      "Imputing row 901/4225 with 29 missing columns, elapsed time: 9.733\n",
      "Imputing row 1001/4225 with 66 missing columns, elapsed time: 9.827\n",
      "Imputing row 1101/4225 with 29 missing columns, elapsed time: 9.927\n",
      "Imputing row 1201/4225 with 26 missing columns, elapsed time: 10.022\n",
      "Imputing row 1301/4225 with 29 missing columns, elapsed time: 10.130\n",
      "Imputing row 1401/4225 with 18 missing columns, elapsed time: 10.235\n",
      "Imputing row 1501/4225 with 89 missing columns, elapsed time: 10.335\n",
      "Imputing row 1601/4225 with 29 missing columns, elapsed time: 10.449\n",
      "Imputing row 1701/4225 with 19 missing columns, elapsed time: 10.555\n",
      "Imputing row 1801/4225 with 70 missing columns, elapsed time: 10.664\n",
      "Imputing row 1901/4225 with 29 missing columns, elapsed time: 10.768\n",
      "Imputing row 2001/4225 with 29 missing columns, elapsed time: 10.866\n",
      "Imputing row 2101/4225 with 19 missing columns, elapsed time: 10.964\n",
      "Imputing row 2201/4225 with 73 missing columns, elapsed time: 11.068\n",
      "Imputing row 2301/4225 with 29 missing columns, elapsed time: 11.186\n",
      "Imputing row 2401/4225 with 29 missing columns, elapsed time: 11.288\n",
      "Imputing row 2501/4225 with 29 missing columns, elapsed time: 11.381\n",
      "Imputing row 2601/4225 with 28 missing columns, elapsed time: 11.482\n",
      "Imputing row 2701/4225 with 37 missing columns, elapsed time: 11.596\n",
      "Imputing row 2801/4225 with 59 missing columns, elapsed time: 11.715\n",
      "Imputing row 2901/4225 with 81 missing columns, elapsed time: 11.819\n",
      "Imputing row 3001/4225 with 90 missing columns, elapsed time: 11.922\n",
      "Imputing row 3101/4225 with 29 missing columns, elapsed time: 12.020\n",
      "Imputing row 3201/4225 with 89 missing columns, elapsed time: 12.131\n",
      "Imputing row 3301/4225 with 29 missing columns, elapsed time: 12.225\n",
      "Imputing row 3401/4225 with 29 missing columns, elapsed time: 12.314\n",
      "Imputing row 3501/4225 with 98 missing columns, elapsed time: 12.415\n",
      "Imputing row 3601/4225 with 18 missing columns, elapsed time: 12.512\n",
      "Imputing row 3701/4225 with 29 missing columns, elapsed time: 12.616\n",
      "Imputing row 3801/4225 with 29 missing columns, elapsed time: 12.718\n",
      "Imputing row 3901/4225 with 102 missing columns, elapsed time: 12.826\n",
      "Imputing row 4001/4225 with 29 missing columns, elapsed time: 12.925\n",
      "Imputing row 4101/4225 with 83 missing columns, elapsed time: 13.028\n",
      "Imputing row 4201/4225 with 29 missing columns, elapsed time: 13.132\n",
      "[KNN] Warning: 10413/464750 still missing after imputation, replacing with 0\n",
      "Computing pairwise distances between 1057 samples\n",
      "Computing distances for sample #1/1057, elapsed time: 0.076\n",
      "Computing distances for sample #101/1057, elapsed time: 0.112\n",
      "No samples have sufficient overlap with sample 116\n",
      "No samples have sufficient overlap with sample 157\n",
      "Computing distances for sample #201/1057, elapsed time: 0.148\n",
      "Computing distances for sample #301/1057, elapsed time: 0.186\n",
      "No samples have sufficient overlap with sample 361\n",
      "Computing distances for sample #401/1057, elapsed time: 0.221\n",
      "Computing distances for sample #501/1057, elapsed time: 0.257\n",
      "Computing distances for sample #601/1057, elapsed time: 0.291\n",
      "Computing distances for sample #701/1057, elapsed time: 0.327\n",
      "Computing distances for sample #801/1057, elapsed time: 0.363\n",
      "Computing distances for sample #901/1057, elapsed time: 0.401\n",
      "Computing distances for sample #1001/1057, elapsed time: 0.436\n",
      "Imputing row 1/1057 with 85 missing columns, elapsed time: 0.512\n",
      "Imputing row 101/1057 with 32 missing columns, elapsed time: 0.559\n",
      "Imputing row 201/1057 with 40 missing columns, elapsed time: 0.608\n",
      "Imputing row 301/1057 with 59 missing columns, elapsed time: 0.653\n",
      "Imputing row 401/1057 with 30 missing columns, elapsed time: 0.701\n",
      "Imputing row 501/1057 with 85 missing columns, elapsed time: 0.751\n",
      "Imputing row 601/1057 with 40 missing columns, elapsed time: 0.798\n",
      "Imputing row 701/1057 with 26 missing columns, elapsed time: 0.851\n",
      "Imputing row 801/1057 with 28 missing columns, elapsed time: 0.895\n",
      "Imputing row 901/1057 with 19 missing columns, elapsed time: 0.944\n",
      "Imputing row 1001/1057 with 29 missing columns, elapsed time: 0.997\n",
      "[KNN] Warning: 1929/116270 still missing after imputation, replacing with 0\n"
     ]
    }
   ],
   "source": [
    "#The imputer. I haven't looked closely at this algo. \n",
    "#Should probably be doing this after standardization because of scaling concerns.\n",
    "from fancyimpute import KNN\n",
    "X_train_filled = pd.DataFrame(KNN(k=3).complete(X_train))\n",
    "X_test_filled = pd.DataFrame(KNN(k=3).complete(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10441, 1936)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Num zero entries\n",
    "(X_train_filled == 0).astype(int).sum().sum(),(X_test_filled == 0).astype(int).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Impute zeros with mean mean.\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values=0, strategy='mean', axis=0)\n",
    "imp.fit(X_train_filled)\n",
    "X_train_filled = pd.DataFrame(imp.transform(X_train_filled))\n",
    "imp.fit(X_test_filled)\n",
    "X_test_filled = pd.DataFrame(imp.transform(X_test_filled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#No zero values\n",
    "(X_train_filled == 0).astype(int).sum().sum(), (X_test_filled == 0).astype(int).sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Standardize\n",
    "from sklearn import preprocessing\n",
    "X_train_preprocessed = pd.DataFrame(preprocessing.scale(X_train_filled))\n",
    "X_test_preprocessed = pd.DataFrame(preprocessing.scale(X_test_filled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit( X_train_preprocessed, np.ravel( (y_train+1)/2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cross_validation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-274-0a6755dafb7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cross_validation' is not defined"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(clf, X_test_preprocessed, np.ravel( (y_test+1)/2), cv=5)\n",
    "\n",
    "scores                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
